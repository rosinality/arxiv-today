https://qwenlm.github.io/blog/qwen3/

*Qwen3: Think Deeper, Act Faster* (Qwen Team)

> 

Qwen 3. 36T 학습했군요. 15T 정도가 SotA의 기준이었는데 이제 30T 이상으로 넘어가는 느낌이네요. PDF에서 텍스트를 추출했다는 것도 이제 공식적으로 이야기하고 있군요. VL 모델들의 최고의 활용처 중 하나가 이 텍스트 추출이 아닌가 싶습니다.

QK Norm을 썼네요. 이쪽 인기가 은근히 오르네요. MoE는 비교적 평이한 구조군요

<english>
Qwen 3. Trained on 36T tokens. Previously 15T was standard of SotA, now it became over than 30T. They are officially says they extracted texts from PDF. I think top application of VL model is this text extraction.

They used QK norm. QK norm gaining some popularity. MoE is rather plain structure.
</english>

#llm 