https://arxiv.org/abs/2506.10395

*Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation* (Zhiyang Xu, Jiuhai Chen, Zhaojiang Lin, Xichen Pan, Lifu Huang, Tianyi Zhou, Madian Khabsa, Qifan Wang, Di Jin, Michihiro Yasunaga, Lili Yu, Xi Victoria Lin, Shaoliang Nie)

> Recent advances in large language models (LLMs) have enabled multimodal foundation models to tackle both image understanding and generation within a unified framework. Despite these gains, unified models often underperform compared to specialized models in either task. A key challenge in developing unified models lies in the inherent differences between the visual features needed for image understanding versus generation, as well as the distinct training processes required for each modality. In this work, we introduce Pisces, an auto-regressive multimodal foundation model that addresses this challenge through a novel decoupled visual encoding architecture and tailored training techniques optimized for multimodal generation. Combined with meticulous data curation, pretraining, and finetuning, Pisces achieves competitive performance in both image understanding and image generation. We evaluate Pisces on over 20 public benchmarks for image understanding, where it demonstrates strong performance across a wide range of tasks. Additionally, on GenEval, a widely adopted benchmark for image generation, Pisces exhibits robust generative capabilities. Our extensive analysis reveals the synergistic relationship between image understanding and generation, and the benefits of using separate visual encoders, advancing the field of unified multimodal models.

이미지 이해와 생성을 위한 토큰을 분리하고 생성 토큰은 MSE로 Autoregressive 예측을 한 다음 Diffusion으로 디코딩하는 꽤 고전적인 접근.

<english>
Quite conventional approach of separating tokens for image understanding and generation, predict generation tokens using autoregression MSE, then decodes with diffusion.
</english>

#autoregressive-model #diffusion #image-generation #multimodal 