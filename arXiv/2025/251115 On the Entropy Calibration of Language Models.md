https://arxiv.org/abs/2511.11966

*On the Entropy Calibration of Language Models* (Steven Cao, Gregory Valiant, Percy Liang)

> We study the problem of entropy calibration, which asks whether a language model's entropy over generations matches its log loss on human text. Past work found that models are miscalibrated, with entropy per step increasing (and text quality decreasing) as generations grow longer. This error accumulation is a fundamental problem in autoregressive models, and the standard solution is to truncate the distribution, which improves text quality at the cost of diversity. In this paper, we ask: is miscalibration likely to improve with scale, and is it theoretically possible to calibrate without tradeoffs? To build intuition, we first study a simplified theoretical setting to characterize the scaling behavior of miscalibration with respect to dataset size. We find that the scaling behavior depends on the power law exponent of the data distribution -- in particular, for a power law exponent close to 1, the scaling exponent is close to 0, meaning that miscalibration improves very slowly with scale. Next, we measure miscalibration empirically in language models ranging from 0.5B to 70B parameters. We find that the observed scaling behavior is similar to what is predicted by the simplified setting: our fitted scaling exponents for text are close to 0, meaning that larger models accumulate error at a similar rate as smaller ones. This scaling (or, lack thereof) provides one explanation for why we sample from larger models with similar amounts of truncation as smaller models, even though the larger models are of higher quality. However, truncation is not a satisfying solution because it comes at the cost of increased log loss. In theory, is it even possible to reduce entropy while preserving log loss? We prove that it is possible, if we assume access to a black box which can fit models to predict the future entropy of text.

생성 결과에 대한 엔트로피와 Log Loss 사이의 차이를 의미하는 LLM의 엔트로피 캘리브레이션에 대한 분석. 규모 증대에 따라 캘리브레이션은 아주 느리게 개선되고 실용적인 대응책은 다양성을 축소시키는 경향이 있음. (다만 이론적으로는 완벽한 캘리브레이션은 가능.)

Entropy calibration of LLMs, which is the difference between entropy over its generations and log loss. This calibration improves very slowly with scale and practical mitigations cause reduced diversity. (But theoretically calibration without tradeoff is possible.)

#llm 