https://arxiv.org/abs/2507.12224

*Optimizers Qualitatively Alter Solutions And We Should Leverage This* (Razvan Pascanu, Clare Lyle, Ionut-Vlad Modoranu, Naima Elosegui Borras, Dan Alistarh, Petar Velickovic, Sarath Chandar, Soham De, James Martens)

> Due to the nonlinear nature of Deep Neural Networks (DNNs), one can not guarantee convergence to a unique global minimum of the loss when using optimizers relying only on local information, such as SGD. Indeed, this was a primary source of skepticism regarding the feasibility of DNNs in the early days of the field. The past decades of progress in deep learning have revealed this skepticism to be misplaced, and a large body of empirical evidence shows that sufficiently large DNNs following standard training protocols exhibit well-behaved optimization dynamics that converge to performant solutions. This success has biased the community to use convex optimization as a mental model for learning, leading to a focus on training efficiency, either in terms of required iteration, FLOPs or wall-clock time, when improving optimizers. We argue that, while this perspective has proven extremely fruitful, another perspective specific to DNNs has received considerably less attention: the optimizer not only influences the rate of convergence, but also the qualitative properties of the learned solutions. Restated, the optimizer can and will encode inductive biases and change the effective expressivity of a given class of models. Furthermore, we believe the optimizer can be an effective way of encoding desiderata in the learning process. We contend that the community should aim at understanding the biases of already existing methods, as well as aim to build new optimizers with the explicit intent of inducing certain properties of the solution, rather than solely judging them based on their convergence rates. We hope our arguments will inspire research to improve our understanding of how the learning process can impact the type of solution we converge to, and lead to a greater recognition of optimizers design as a critical lever that complements the roles of architecture and data in shaping model outcomes.

Optimizer가 Inductive Bias를 부여한다는 주장. 자연스럽죠. 따라서 Optimizer를 조작해서 특정한 Inductive Bias를 부여할 수도 있습니다. 그런데 어떤 Inductive Bias가 이상적인가? 이는 논문에서도 인정하듯 어려운 문제죠. 다만 실용적으로는 Optimizer의 차이에 의한 결과의 차이를 고려해야 한다고 생각할 수 있겠네요. Kimi K2에 대해서도 Muon의 사용이 모델에 어떤 질적인 차이를 주지 않았을까 하는 생각을 많이 하더군요.

<english>
An insist of optimizer induces certain inductive biases. It is natural. Thus we can induce certain inductive biases by modifying optimizers. But which inductive biases would be ideal? It is hard problem, as they acknowledges in the paper. But we can think, practically, we should consider the difference in solutions induced by optimiezr differences. Many people also thinks whether it is possible for Kimi K2 have qualitative differences due to its use of Muon.
</english>

#optimization 