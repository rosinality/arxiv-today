https://arxiv.org/abs/2510.11690

*Diffusion Transformers with Representation Autoencoders* (Boyang Zheng, Nanye Ma, Shengbang Tong, Saining Xie)

> Latent generative modeling, where a pretrained autoencoder maps pixels into a latent space for the diffusion process, has become the standard strategy for Diffusion Transformers (DiT); however, the autoencoder component has barely evolved. Most DiTs continue to rely on the original VAE encoder, which introduces several limitations: outdated backbones that compromise architectural simplicity, low-dimensional latent spaces that restrict information capacity, and weak representations that result from purely reconstruction-based training and ultimately limit generative quality. In this work, we explore replacing the VAE with pretrained representation encoders (e.g., DINO, SigLIP, MAE) paired with trained decoders, forming what we term Representation Autoencoders (RAEs). These models provide both high-quality reconstructions and semantically rich latent spaces, while allowing for a scalable transformer-based architecture. Since these latent spaces are typically high-dimensional, a key challenge is enabling diffusion transformers to operate effectively within them. We analyze the sources of this difficulty, propose theoretically motivated solutions, and validate them empirically. Our approach achieves faster convergence without auxiliary representation alignment losses. Using a DiT variant equipped with a lightweight, wide DDT head, we achieve strong image generation results on ImageNet: 1.51 FID at 256x256 (no guidance) and 1.13 at both 256x256 and 512x512 (with guidance). RAE offers clear advantages and should be the new default for diffusion transformer training.

엄청난 결과! 프리트레이닝된 ViT 인코더를 차원 축소 없이 그대로 이미지 토크나이저로 사용. DiT는 보통 이런 고차원 Latent에서는 작동하지 않음. 그 이유는 네트워크의 폭이 Latent보다 작고 노이즈 스케줄이 Latent 차원에 따라 조정되어야 하기 때문. Gaussian 노이즈를 추가하면 데이터 매니폴드가 Full Dimension이 되므로 네트워크의 폭 또한 같이 증가해야 하는 것이 당연. 발견된 이후에야 자명하게 느껴지는 사실.

Groundbreaking work! Using a pretrained ViT encoder as an image tokenizer without dimensionality reduction. Normally DiT wouldn't work with these high-dimensional latents. The reason is that the network's width is narrower than the latents, and the noise schedule should be adjusted according to latent dim. Adding gaussian noise makes the data manifold full-dimensional so the network width should naturally be increased accordingly. An obvious fact only after it's discovered.

#tokenizer #diffusion 