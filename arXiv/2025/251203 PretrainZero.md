https://arxiv.org/abs/2512.03442

*PretrainZero: Reinforcement Active Pretraining* (Xingrun Xing, Zhiyuan Fan, Jie Lou, Guoqi Li, Jiajun Zhang, Debing Zhang)

> Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.

프리트레이닝 코퍼스에 대한 RL. 기본적으로 Exact Match를 보상으로 사용한 마스킹된 단어 예측. 주요 기여점은 어떤 단어를 마스킹할 것인지를 선택하는 것. 예측 불가능한 마스크에 페널티를 주는 상황에서 마스크 생성 모델과 단어 예측 모델 사이의 Adversarial Training을 사용.

RL training on pretraining corpus. Basically masked word prediction with exact match reward. Main contribution is how to mask some words. They did adversarial training between mask generator and word predictor that penalizes unpredictable masks.

#rl #pretraining #synthetic-data 