https://arxiv.org/abs/2502.07316

*CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction* (Junlong Li, Daya Guo, Dejian Yang, Runxin Xu, Yu Wu, Junxian He)

> Reasoning is a fundamental capability of Large Language Models. While prior research predominantly focuses on enhancing narrow skills like math or code generation, improving performance on many other reasoning tasks remains challenging due to sparse and fragmented training data. To address this issue, we propose CodeI/O, a novel approach that systematically condenses diverse reasoning patterns inherently embedded in contextually-grounded codes, through transforming the original code into a code input-output prediction format. By training models to predict inputs/outputs given code and test cases entirely in natural language as Chain-of-Thought (CoT) rationales, we expose them to universal reasoning primitives -- like logic flow planning, state-space searching, decision tree traversal, and modular decomposition -- while decoupling structured reasoning from code-specific syntax and preserving procedural rigor. Experimental results demonstrate CodeI/O leads to consistent improvements across symbolic, scientific, logic, math & numerical, and commonsense reasoning tasks. By matching the existing ground-truth outputs or re-executing the code with predicted inputs, we can verify each prediction and further enhance the CoTs through multi-turn revision, resulting in CodeI/O++ and achieving higher performance. Our data and models are available at https://github.com/hkust-nlp/CodeIO.

코드를 사용해 자연어 CoT의 능력을 높이자는 아이디어. 코드를 적당한 포맷으로 가공한 다음 입력 혹은 출력에서 출력 혹은 입력을 예측하도록 학습시키는군요.

응답을 실행 결과로 필터링하는 것이 자연스럽지만 여기에서는 이 필터링이 들어가는 쪽이 오히려 좋지 않았다고 하네요. 대신 Revision을 하도록 유도했군요.

<english>
The idea of improving natural language CoT by using codes. First preprocess codes into adequate formats and train model to generate output or inputs from input or outputs.

It feels natural to filter responses using execution results but this paper says that actually filtering like this decreased model performance. Instead, they let model to revise response using execution feedbacks.
</english>

#synthetic-data #reasoning 