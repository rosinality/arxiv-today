https://arxiv.org/abs/2312.14125

VideoPoet: A Large Language Model for Zero-Shot Video Generation (Dan Kondratyuk, Lijun Yu, Xiuye Gu, José Lezama, Jonathan Huang, Rachel Hornung, Hartwig Adam, Hassan Akbari, Yair Alon, Vighnesh Birodkar, Yong Cheng, Ming-Chang Chiu, Josh Dillon, Irfan Essa, Agrim Gupta, Meera Hahn, Anja Hauth, David Hendon, Alonso Martinez, David Minnen, David Ross, Grant Schindler, Mikhail Sirotenko, Kihyuk Sohn, Krishna Somandepalli, Huisheng Wang, Jimmy Yan, Ming-Hsuan Yang, Xuan Yang, Bryan Seybold, Lu Jiang)

https://sites.research.google/videopoet/

구글의 비디오 생성 모델. Discrete Token 기반 Autoregressive 생성이군요. MAGViT-v2 (Lookup-Free Quantization) 기반으로 토크나이즈를 했네요. 오디오도 마찬가지로 토크나이즈를 해서 오디오 입출력이 가능하게 했습니다.

상당히 흥미로운 디자인이네요. 텍스트, 이미지, 비디오, 오디오 같은 서로 다른 모달리티를 넘나드는 생성이 가능하다는 것이 중요한 부분이 아닐까 싶습니다. 비디오 생성 쪽의 Breakthrough를 기대하는 사람들이 많은 듯 하던데 제미니의 다음 모델에는 비디오 생성이 들어갈 것 같네요.

#video_generation #autoregressive_model #audio_generation #multimodal  