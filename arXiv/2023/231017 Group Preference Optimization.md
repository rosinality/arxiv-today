https://arxiv.org/abs/2310.11523

Group Preference Optimization: Few-Shot Alignment of Large Language Models (Siyan Zhao, John Dang, Aditya Grover)

어쩐지 서로 통하는 문제를 다른 관점에서 풀고 있다는 느낌이 드네요. 서로 다른 집단의 서로 다른 선호에 어떻게 맞출 수 있을 것인가? 여기에서는 Preference Model을 few shot classifier로 만드는 방식이군요. 몇 가지 선호 패턴 데이터를 입력으로 주면 다른 선호 결과를 예측할 수 있게 하겠다는 접근입니다.

#rl #alignment 

[[231017 Personalized Soups]]