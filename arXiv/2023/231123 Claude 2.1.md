https://www.anthropic.com/index/claude-2-1

Claude 2.1이 나왔군요. 200K context length, 할루시네이션을 절반으로 억제, 도구 사용, 시스템 프롬프트 등을 추가했군요.

https://x.com/GregKamradt/status/1727018183608193393
200K context length에 대한 retrieval 테스트 결과입니다. 다만 이런 종류의 과제에서는 long context 능력에 더해 관계 없는 맥락 텍스트를 다루는 능력 자체도 필요하다는 생각이 드네요.

#llm 