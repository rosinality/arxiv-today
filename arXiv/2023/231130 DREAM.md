https://arxiv.org/abs/2312.00210

DREAM: Diffusion Rectification and Estimation-Adaptive Models (Jinxin Zhou, Tianyu Ding, Tianyi Chen, Jiachen Jiang, Ilya Zharkov, Zhihui Zhu, Luming Liang)

https://www.tianyuding.com/projects/DREAM/

diffusion 모델이 학습 시에는 ground truth에 접근 가능하고 추론 시에는 노이즈에서 작동한다는 것으로 인해 발생하는 갭을 줄이기 위한 방법. diffusion의 학습/추론 갭에 대한 문제는 다른 지점에서도 나왔었는데 (https://arxiv.org/abs/2305.08891) 이쪽은 더 과감하군요.

대응 방법은 학습 시에 모델의 출력으로 디노이징해서 타겟 이미지를 만든 다음 이 타겟 이미지에 대해 다시 학습시키는 것입니다. 더 빠른 수렴과 성능 향상이 나타나는 군요. 선사 시대 방법이지만 Scheduled Sampling (https://arxiv.org/abs/1506.03099) 같은 것도 생각나고 그렇습니다.

#diffusion

# Links

[[230515 Common Diffusion Noise Schedules and Sample Steps are Flawed.md]]