https://arxiv.org/abs/2307.05222

Generative Pretraining in Multimodality (Quan Sun, Qiying Yu, Yufeng Cui, Fan Zhang, Xiaosong Zhang, Yueze Wang, Hongcheng Gao, Jingjing Liu, Tiejun Huang, Xinlong Wang)

Emu (https://arxiv.org/abs/2307.05222) 의 버전 2. 더 큰 모델을 Grounding 데이터셋을 포함시켜서 학습하고, Causal Transformer를 빼고 Visual Decoder를 Visual Encoder의 출력에 대해 바로 학습시키는 더 단순한 세팅을 사용했네요. In-context learning이라거나 레이아웃을 사용한 이미지 생성 등의 예제를 보여주고 있습니다.

Visual Decoder 까지 같이 학습될 수 있으면 더 좋을 것 같긴 한데 이게 좀 까다롭군요. 아예 픽셀 기반으로 움직이는 사례가 나올 것 같기도 하네요.

#multimodal #in_context_learning #image_generation #vision-language

# Links

[[230711 Generative Pretraining in Multimodality.md]]