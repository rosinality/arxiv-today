https://arxiv.org/abs/2310.00492

From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning (Xuansheng Wu, Wenlin Yao, Jianshu Chen, Xiaoman Pan, Xiaoyang Wang, Ninghao Liu, Dong Yu)

Instruction tuning 과정에서 모델에는 어떤 변화가 발생하는가? 일단 instruction에 해당하는 토큰에 대한 attention weight가 증가하고, 학습에 사용된 instruction 시나리오에 관련된 방향으로 ffn에 인코딩된 지식의 분포가 변화하고, instruction에 자주 등장하는 동사에 대한 attention이 증가하는 군요. 얻을 수 있는 통찰은 여럿이겠지만 전 instruction tuning에 사용되는 데이터셋의 다양성이 아주 중요하다는 것을 시사하는 증거로 보이네요.

#instruction-tuning 

[[231115 Never Lost in the Middle]]