https://arxiv.org/abs/2309.16609

Qwen Technical Report (Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, Tianhang Zhu)

알리바바의 LLM. 14B 모델을 3T 토큰에 대해 학습시켰고, 코드 모델도 만들었군요. 요즘 그렇듯 데이터셋 구성에 대해서는 그렇게 말을 많이 하고 있진 않습니다. 그래도 여기 나와있는 정도면 대략적이나마 기술했다고 할 수 있을 것 같기도 하네요.

요즘 나오는 모델들은 alignment 까지 거치고 나오고 있는데, 그래서 오히려 이쪽에 흥미로운 포인트들이 조금 더 있는 것 같네요. reward model을 위한 데이터의 구성 방법 등등.

#llm #alignment 