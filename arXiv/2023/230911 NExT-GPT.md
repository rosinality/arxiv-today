https://arxiv.org/abs/2309.05519

NExT-GPT: Any-to-Any Multimodal LLM (Shengqiong Wu, Hao Fei, Leigang Qu, Wei Ji, Tat-Seng Chua)

multimodal input & generation을 지원하는 모델. 이쪽은 특정 modal의 인코더의 projection을 입력에 사용하는 것처럼 특정 modal의 디코더 (diffusion model)을 위한 임베딩을 projection으로 생성하게 만드는 식으로 연결했군요. 거기에 더해 multimodal generation을 위한 instruction 데이터셋을 구축.

#multimodal #vision-language #multimodal_generation 