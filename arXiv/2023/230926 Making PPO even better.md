https://arxiv.org/abs/2309.15028

Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding (Jiacheng Liu, Andrew Cohen, Ramakanth Pasunuru, Yejin Choi, Hannaneh Hajishirzi, Asli Celikyilmaz)

PPO 학습된 모델과 Value function을 가져와서 MCTS로 토큰 디코딩을 시도. 말만 들어도 비싼 방법이라 대략 20 토큰 정도의 길이로만 테스트했네요. 비용 문제는 차치하고 전 서치가 흥미로운 방향이 아닌가 싶습니다. The Bitter Lesson에서 AI 발전에서 가장 효과적이었던 두 가지로 학습과 서치를 언급했던 것을 생각하면요.

#rl #search #decoding 