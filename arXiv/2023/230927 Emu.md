https://arxiv.org/abs/2309.15807

Emu: Enhancing Image Generation Models Using Photogenic Needles in a Haystack (Xiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam Tsai, Jialiang Wang, Rui Wang, Peizhao Zhang, Simon Vandenhende, Xiaofang Wang, Abhimanyu Dubey, Matthew Yu, Abhishek Kadian, Filip Radenovic, Dhruv Mahajan, Kunpeng Li, Yue Zhao, Vladan Petrovic, Mitesh Kumar Singh, Simran Motwani, Yi Wen, Yiwen Song, Roshan Sumbaly, Vignesh Ramanathan, Zijian He, Peter Vajda, Devi Parikh)

프리트레이닝한 Diffusion 모델을 필터링과 사람의 큐레이션으로 선정한 단 2천 장의 데이터로 파인튜닝 했을 때 생성 이미지의 퀄리티가 대폭 상승한다는 결과.

비교적 낮은 퀄리티의 데이터로 프리트레이닝 - 높은 퀄리티의 데이터로 파인튜닝이라는 공식이 성공적으로 작동하고 있네요. (https://arxiv.org/abs/2305.11206) 기존에는 딥 러닝은 전자, 낮은 퀄리티더라도 데이터 양을 증가시키는 것에 관심이 더 높았다고 할 수 있을 텐, 지금은 파인튜닝을 위해 데이터의 퀄리티를 최대한 끌어올리는 것의 중요성이 높아지고 있다고 볼 수 있지 않을까 싶습니다. 그런데 이 두 가지 방향은 데이터의 수집과 구축 과정에서 서로 다른 요구 사항을 발생시키죠. 이 논문의 경우에도 필터링을 위해 자동화된 필터링을 한 번 하고, 사람을 통해 필터링할 때에도 첫 단계로 일반적인 어노테이터들로 한 번 필터링한 다음 사진에 대한 이해가 있는 어노테이터들로 다시 한 번 필터링하는 흐름으로 진행했습니다. 그 과정에서 어떤 것이 더 높은 퀄리티의 이미지인가라는 기준에 대한 정립이 필요했고요.

#ddpm

# Links

[[230518 LIMA.md]]
