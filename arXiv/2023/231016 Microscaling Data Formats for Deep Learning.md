https://arxiv.org/abs/2310.10537

Microscaling Data Formats for Deep Learning (Bita Darvish Rouhani, Ritchie Zhao, Ankit More, Mathew Hall, Alireza Khodamoradi, Summer Deng, Dhruv Choudhary, Marius Cornea, Eric Dellinger, Kristof Denolf, Stosic Dusan, Venmugil Elango, Maximilian Golub, Alexander Heinecke, Phil James-Roxby, Dharmesh Jani, Gaurav Kolhe, Martin Langhammer, Ada Li, Levi Melnick, Maral Mesmakhosroshahi, Andres Rodriguez, Michael Schulte, Rasoul Shafipour, Lei Shao, Michael Siu, Pradeep Dubey, Paulius Micikevicius, Maxim Naumov, Colin Verilli, Ralph Wittig, Eric Chung)

blockwise scale exponent를 가지고 low precision fp training/inference를 해보려는 시도군요. MS, AMD, Intel, Meta, NVIDIA, Qualcomm에서 모두 참여했네요. 이런 방법으로 FP8 이하로 내려가 보려고 하는 것일까 하는 생각이 듭니다.

#efficient_training 