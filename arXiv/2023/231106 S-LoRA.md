https://arxiv.org/abs/2311.03285

S-LoRA: Serving Thousands of Concurrent LoRA Adapters (Ying Sheng, Shiyi Cao, Dacheng Li, Coleman Hooper, Nicholas Lee, Shuo Yang, Christopher Chou, Banghua Zhu, Lianmin Zheng, Kurt Keutzer, Joseph E. Gonzalez, Ion Stoica)

다양한 lora를 배치 처리하고 효율적으로 추론하는 문제에 대한 대응. lora를 합치는 대신 기본 weight로 matmul을 하고, lora에 대해서는 배치 처리를 위한 커스텀 커널을 만들었군요. 거기에 같은 lora를 쓰는 리퀘스트들끼리 묶는다거나 paged attention을 확장해 lora weight를 올려놓는다거나 하는 최적화들도 들어갔습니다.

당연히 바닐라 모델이나 lora merge를 한 모델보다는 퍼포먼스가 떨어질 수밖에 없긴 한데...그럭저럭 할만해 보이는 것 같이 보이기도 하네요. 배치 처리가 쉬운 어댑터를 쓰는 쪽이 맞지 않을까 싶었는데 이렇게까지 만든 시스템이 있다고 하면 lora를 고려해볼만할 것 같네요.

#efficiency #adapter 