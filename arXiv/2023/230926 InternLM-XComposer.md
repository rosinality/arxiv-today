https://arxiv.org/abs/2309.15112

InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition (Pan Zhang, Xiaoyi Dong Bin Wang, Yuhang Cao, Chao Xu, Linke Ouyang, Zhiyuan Zhao, Shuangrui Ding, Songyang Zhang, Haodong Duan, Hang Yan, Xinyue Zhang, Wei Li, Jingwen Li, Kai Chen, Conghui He, Xingcheng Zhang, Yu Qiao, Dahua Lin, Jiaqi Wang)

Interleaved Vision-Language 모델은 이제 기본이군요. EVA-CLIP (https://arxiv.org/abs/2211.07636) Vision 인코더 + InternLM (https://github.com/InternLM/InternLM) Language 디코더에 Perceiver 스타일 샘플러를 붙였군요. 이쪽은 BLIP-2 (https://arxiv.org/abs/2301.12597) 의 차용으로 보이긴 합니다만.

이렇게 모아보니 중국 내에서 자체 구축한 모델로 구성되었다는 게 눈에 띄기도 하네요. 추가로 InternLM의 정체도 궁금하군요.

#vision-language #multimodal

# Links

[[221114 EVA.md]]