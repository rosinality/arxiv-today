https://arxiv.org/abs/2309.09055

Exploring the impact of low-rank adaptation on the performance, efficiency, and regularization of RLHF (Simeng Sun, Dhawal Gupta, Mohit Iyyer)

ppo에서 lora가 괜찮더라는 결과. 사실 그 이야기만 하는 것은 아니고 lora 적용 시 kl penalty가 없어도 그럭저럭 괜찮았다 같은 발견도 있습니다. factuality 벤치마크 결과에서 긍정적인 결과도 발견했네요. low rank update라는 것 자체에 너무 많은 것을 기대하고 있지 않은가 하는 생각도 있긴 합니다만...

#efficient_training #rl 