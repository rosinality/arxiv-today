https://arxiv.org/abs/2310.20550

CapsFusion: Rethinking Image-Text Data at Scale (Qiying Yu, Quan Sun, Xiaosong Zhang, Yufeng Cui, Fan Zhang, Xinlong Wang, Jingjing Liu)

요즘 이미지-텍스트 데이터셋에 캡션 다시 달기가 유행인데, 캡션을 생성해봤더니 깨끗하긴 하지만 캡션에 포함된 정보가 부족하더라, 그에 반해 원 데이터는 노이즈가 많지만 정보가 풍부하더라 하는 발견에서 시작한 연구네요. 생성한 캡션과 원 텍스트를 결합해서 ChatGPT로 개선한 텍스트를 가지고 캡션 개선 모델을 만들어서 데이터셋을 구축했습니다.

캡션 모델, 데이터셋의 원 텍스트, 이미지와 텍스트라는 각각의 modal을 어떻게 결합해서 더 나은 이미지-텍스트 데이터를 구축할 것인가가 꽤 흥미롭고 중요한 주제인 것 같네요.

#captioning #vision-language #multimodal #dataset 

[[231020 DALL-E 3]]