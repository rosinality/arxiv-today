https://arxiv.org/abs/2309.07120

Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness and Ethics (Haoqin Tu, Bingchen Zhao, Chen Wei, Cihang Xie)

CC3M과 LLaVA (https://arxiv.org/abs/2304.08485) 의 데이터로 튜닝했더니 TruthfulQA 스코어가 향상되더라는 발견. 이미지 빼고 텍스트만으로도 향상이 있긴 하군요. 이미지-텍스트 데이터에서 텍스트의 특정한 패턴 때문에 향상이 있을 수도 있고 LLaVA 같은 데이터에서 뭔가가 있었을 수도 있을 것 같고 그렇네요. 이미지-텍스트 데이터의 어떤 긍정적인 패턴이 있다고 하면 좋은 일이겠지만요.

#vision-language #multimodal

# Links

# Links

