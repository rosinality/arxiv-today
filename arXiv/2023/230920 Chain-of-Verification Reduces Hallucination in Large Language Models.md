https://arxiv.org/abs/2309.11495

Chain-of-Verification Reduces Hallucination in Large Language Models (Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, Jason Weston)

할루시네이션을 억제하는 프롬프팅. 일단 답을 생성하고, 답의 팩트 체크를 위한 질문들을 생성하고, 그 질문에 대해 응답하고, 그 결과를 사용해 답을 개선하는 방식입니다.

Sparks of AGI (https://www.youtube.com/watch?v=qbIk7-JPB2c&t=2385s) 에서도 언급 됐던 부분인데 현재 LLM의 문제 중 하나는 너무 빨리 답을 생성하려는 경향이 아닌가 싶네요.

#hallucination #prompt 