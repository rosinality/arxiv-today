https://arxiv.org/abs/2311.13133

LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms (Aditi Jha, Sam Havens, Jeremey Dohmann, Alex Trott, Jacob Portes)

LIMA와 Instruct 데이터셋(HH-RLHF, Dolly-15K, 그리고 여러 데이터셋들)을 통해 튜닝했을 때 성능 변화에 대한 실험. 전통적인 NLP 과제에서는 Instruct 데이터셋이 좋았고, LIMA 테스트셋으로 GPT-4 평가를 했을 때는 당연하게도(?) LIMA가 좋았다, 그래서 다양한 데이터셋을 섞는 것은 좋은 것 같다, 그렇지만 데이터셋이 많을 필요는 없는 것 같다는 결론입니다.

#instruction-tuning 

[[230518 LIMA]]