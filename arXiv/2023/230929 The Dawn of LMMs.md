https://arxiv.org/abs/2309.17421

The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision) (Zhengyuan Yang, Linjie Li, Kevin Lin, Jianfeng Wang, Chung-Ching Lin, Zicheng Liu, Lijuan Wang)

Multimodal GPT-4로 할 수 있는 과제들, 그리고 프롬프팅 방법에 대한 리포트. 엄청나게 많은 과제가 가능하네요. 이미지 입력이 가능하니 이미지에 그리는 방식으로 프롬프팅을 하는 것도 가능해지는 군요. CVPR에서 Multimodal GPT-4가 나오면 지금 나오고 있는 논문의 80%가 영향력을 잃어버릴 것이라는 이야기가 나왔다는데...그게 사실이 되지 않을까 싶습니다.

Multimodal GPT-4가 열려서 이전에 하던 과제를 하나 테스트해봤는데 상당히 잘 되는 것 같습니다. 두려운 것은 이게 그저 시작일 뿐이라는 것이겠죠. OpenAI는 다음 단계로 scratch 학습된 Multimodal 모델을 준비 중이라고 하는데(혹은 이미 갖고 있다는 소문도?) 그건 대체 어느 정도의 성능으로 등장할지 상상하기도 쉽지 않네요.

#multimodal #multitask #vision-language #llm 