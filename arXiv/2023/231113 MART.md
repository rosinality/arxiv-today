https://arxiv.org/abs/2311.07689

MART: Improving LLM Safety with Multi-round Automatic Red-Teaming (Suyu Ge, Chunting Zhou, Rui Hou, Madian Khabsa, Yi-Chia Wang, Qifan Wang, Jiawei Han, Yuning Mao)

LLM으로 red-teaming을 하는 방법이군요. 일단 시드 프롬프트로 새로운 프롬프트를 생성하게 한 다음, 공격에 성공한 프롬프트를 모아 red-teaming 모델을 학습시키고, 방어에 성공한 응답을 모아 목표 모델을 학습시키는 방법이네요. 공격 프롬프트를 생성한다는 것은 흥미로운데 이 과정에서 프롬프트가 얼마나 정교해질 수 있는지는 궁금하네요.

#safety 