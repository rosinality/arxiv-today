https://arxiv.org/abs/2308.07921

Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification (Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, Hongsheng Li)

코드 사용이 LLM의 문제 해결 능력에 어떤 영향을 미치는지 테스트. GPT-4 코드 인터프리터를 사용해서 프롬프트로 코드 사용 횟수를 정해준 다음에 성능이 어떻게 변화하는지를 일단 관측했다. 코드 사용 횟수가 늘어날수록 성능이 향상된다는 것이 나타난다. 

여기에 Verification을 유도하는 프롬프트를 사용해고, k개 샘플을 뽑은 뒤 Verification 결과로 Voting하게 만드니 50점대 점수가 나오던 MATH에서 84.32 (!)에 도달했다. 굉장한 수준의 점프.

Verification을 유도하는 프롬프트는 "To solve the problem using code interpreter step by step, and please verify your answer using code interpreter." 인데 이게 Let's think step by step을 잇는 다음 세대의 매직 프롬프트가 되지 않을까.

파이썬 인터프리터 등을 사용해서 코드를 실행하고 그 결과를 사용하는 접근은 이전에도 자주 나왔지만, 코드 작성, 실행, 결과를 사용해서 다시 피드백 루프까지 돌아가는 모델이 기성품(?)으로 나와 있으니 그 위력이 더 뚜렷하게 보이는 듯 싶다.

이 결과를 보면서 LLM에는 외부 세계와 상호작용하고, 자신의 액션의 결과를 피드백할 수 있는 구조가 중요하다는 생각을 한다. 물론 이 피드백된 결과를 반영해서 더 개선된 액션과 판단을 생성할 수 있게 되는 능력도 중요하겠다. Reward Model이 어느 정도 대신해줄 수는 있겠지만 한계는 명백하다.

그렇지만 외부 세계와 연결하는 이 작업이 정말로 까다로워 보인다. 코드나 코드 인터프리터 쪽에서 발전이 뚜렷한 것도 그나마 쉽게 할 수 있는 영역이기 때문일 것이다. 하다못해 오피스 같은 프로그램을 연결하는 것만 해도 훨씬 더 까다로울 것이다. (거기에 지금도 모델이 서버를 뚫고 나가는 것을 염려하고 있는데 세계와 연결된 인터페이스를 추가한다니...안전의 측면에서도 너무 위험하지 않겠나?)

이건 여기까지 하고, 이전부터 LLM이 더 큰 가치를 창출하기 위해서는 어떻게 되어야 하는가 하는 생각을 했다. 어쨌든 AI는 인간이 하는 작업을 대체해야 가장 직접적인 가치가 발생할 것이다. 그런데 인간이 하는 작업을 대체하려면 어떻게 해야 하는가? 아니, 도대체 인간이 하는 일이란 어떠한 것인가?

인간이 수행하는 일을 대체하려면 인간이 하는 일에 대해서 깊게 이해해야 한다고 생각한다. 어떤 경우에는 이런 걸 자동화하면 사람들이 편리하게 생각할 것이다 정도의 추측 정도로 제품이 만들어지는 경우도 있는 것 같다. 그걸로도 충분할 수도 있겠지만, 한계가 있는 경우도 분명히 많을 것이다.

AI가 사무직을 대체할 것이라고들 하는데 애초에 사무직은 어떤 일을 하고 있는가? 그들이 가장 많은 시간을 쓰고 있는 것은 어떤 일들인가? 그들이 가장 까다롭게 생각하는 것은 무엇인가? 그들의 업무의 다양성은 어떠한가? 우리는 그것에 대해서 충분히 깊게 이해하고 있을까? 이는 여러분이 하는 일은 무엇인가라고 묻는다고 해도 제대로 알 수 있는 것이 아니다.

그리고 모델이 그들의 업무를 대체하기 위해서는 무엇이 가능해야 하는가? 솔직히 사무직은 커녕 프로그래머의 업무도 충분히 깊게 이해하고 있다고 말하기 어려운 터라 그에 대해서 논하기가 어렵다. 그렇지만 일상적이고 소소한 일들에 대해서도 거기에 나타나는 인간의 유연함과 대처 능력은 상상을 뛰어넘는다는 생각을 한다.

인간의 일이라는 것을 충분히 이해하고 있지 않다는 것은 인정하지만, 그래도 AI가 인간의 작업을 대신할 수준이 되려면 어떤 것이 가능해야 하는가를 추측해보게 된다. 나는 거기에 자율적인 행위자로서 작동할 수 있는 AI 모델, 혹은 단순히 모델을 뛰어넘는 시스템이 필요하지 않을까 하는 생각을 한다. 업무의 특정 단계들을 사람이 하나하나 지시하고, 그 지시 결과에 따라 자동화된 결과물이 나오는 정도가 아니라 지시에 대해 스스로 판단해서, 그 지시에 따르기 위한 작업들을 계획하고, 세상과 상호작용하면서 그 결과에 따라 피드백으로 작업을 개선하는 수준의 행위자가 된다면 실제 업무들을 거시적인 수준에서 자동화하는 것이 가능하지 않을까 하는 생각이다.

예를 들면 Auto GPT 같은 사례처럼. Auto GPT는 실제로 잘 되지 않는다는 지적이 많았지만, 나는 반대로 그런 접근이 정말로 잘 동작한다면 그것이 실제로 유용할지가 궁금하다. (Andrew Ng이 음성 인식의 정확도가 95%라면 아무도 쓰지 않겠지만 99%라면 모두가 쓰게 될 것이라고 했던 표현을 기억한다. 스무 단어 중 하나를 틀리는 것과 백 단어 중 하나를 틀리는 것은 엄청난 차이이므로. 자율적인 행위자가 99%의 경우에 잘 작동하면 모두가 쓰게 될까?)

그리고 코드 인터프리터를 보면서 이런 자율적인 행위자로서의 AI의 가능성에 대해 생각해보게 된다. 이런 식으로 계획하고, 실행하고, 결과를 피드백해서 다음 액션을 계획하는 AI가 더 큰 규모의 코드에 대해서도 잘 작동하게 될 수 있을까? 코드가 아니라 세상에 대한 다른 액션에 대해서도 작동하게 될 수 있을까? 그게 코드 인터프리터가 보여주는 가능성에서 흥미로운 지점이라고 생각한다.

Claude 2에 대해서, 현 수준의 LLM이 실용적으로 의미가 있는 영역은 텍스트 조작과 생성이고, 따라서 GPT-4와 같은 수준의 추론 능력은 필요하지 않은 경우가 많기에, 그보다 저렴하면서도 작문 능력이 뛰어난 모델이 경쟁력이 있을 수 있다는 이야기를 들은 적이 있다. 플러그인이나 코드 인터프리터 같은 것도 여전히 그러한 상태일 수 있다. 분명 놀랍지만 지금은 95%의 음성 인식과 비슷한 상태일 수 있다. 충분히 잘 작동하지 않거나, 혹은 가능한 것이 그렇게 많지 않기에 과도하다고 여겨질 수도 있다.

그렇지만 만약 이러한 시도의 이후 미래에 99%의 지점에 도달할 수 있다면? 그때는 작문 능력과 같은 문제에 대해서 논하는 것 자체가 불필요해지게 될 수도 있겠다는 생각을 한다. 그때는 더 정확한가 그렇지 않은가 정도의 문제를 넘어 가능한지 혹은 가능하지 않은지의 수준에서 격차가 발생하는 시점이 될 것이다. 물론 전적으로 행위자로서의 AI가 정말로 유용하다는 추측이 맞을 때의 이야기이지만.