https://arxiv.org/abs/2310.09199

PaLI-3 Vision Language Models: Smaller, Faster, Stronger (Xi Chen, Xiao Wang, Lucas Beyer, Alexander Kolesnikov, Jialin Wu, Paul Voigtlaender, Basil Mustafa, Sebastian Goodman, Ibrahim Alabdulmohsin, Piotr Padlewski, Daniel Salz, Xi Xiong, Daniel Vlasic, Filip Pavetic, Keran Rong, Tianli Yu, Daniel Keysers, Xiaohua Zhai, Radu Soricut)

이미지와 텍스트 토큰을 인코더 입력으로 사용하는 seq2seq 모델. 인코더-디코더 모델에 SigLIP, UL2 등 구글이 좋아하는 고전적인 스타일의 취가 물씬 풍기는 군요. 개인적으로 multimodal input/output의 가장 효과적인 결합 방식이 궁금하긴 합니다. 물론 규모가 커지면 뭐든 괜찮겠지만 약간 더 효율성을 높인다는 측면에서...

#multimodal #vision-language #seq2seq 