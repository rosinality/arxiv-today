https://arxiv.org/abs/2309.08168

Draft & Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding (Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Sharad Mehrotra)

speculative sampling에서 drafting을 작은 llm이 아니라 큰 llm + 레어이 건너뛰기으로 대체한 방법. 건너뛸 레이어는 최적화로 찾아봤습니다. layer skipping을 이렇게 활용했다는 것 자체가 재밌네요.

#efficiency 

[[230202 Accelerating Large Language Model Decoding with Speculative Sampling]]