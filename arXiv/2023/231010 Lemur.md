https://arxiv.org/abs/2310.06830

Lemur: Harmonizing Natural Language and Code for Language Agents (Yiheng Xu, Hongjin Su, Chen Xing, Boyu Mi, Qian Liu, Weijia Shi, Binyuan Hui, Fan Zhou, Yitao Liu, Tianbao Xie, Zhoujun Cheng, Siheng Zhao, Lingpeng Kong, Bailin Wang, Caiming Xiong, Tao Yu)

코드와 자연어 둘 다 잘 하는 모델을 만들자는 기획. 사실 CodeLlama의 70B 버전 같은 느낌이 있긴 있습니다. (자연어-코드 비율 1:10으로 프리트레이닝, SFT 등.) 다만 모델 크기의 차이인지 데이터셋 구성의 디테일 차이인지 CodeLlama 34B와는 벤치마크 스코어가 좀 다르긴 하네요. 여하간 이걸로 Agent 구현에 필요한 능력에 있어 향상이 있었다는 이야기를 하고 있습니다.

#llm 