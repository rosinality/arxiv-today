https://arxiv.org/abs/2412.14170

*E-CAR: Efficient Continuous Autoregressive Image Generation via Multistage Modeling* (Zhihang Yuan, Yuzhang Shang, Hanling Zhang, Tongcheng Fang, Rui Xie, Bingxin Xu, Yan Yan, Shengen Yan, Guohao Dai, Yu Wang)

> Recent advances in autoregressive (AR) models with continuous tokens for image generation show promising results by eliminating the need for discrete tokenization. However, these models face efficiency challenges due to their sequential token generation nature and reliance on computationally intensive diffusion-based sampling. We present ECAR (Efficient Continuous Auto-Regressive Image Generation via Multistage Modeling), an approach that addresses these limitations through two intertwined innovations: (1) a stage-wise continuous token generation strategy that reduces computational complexity and provides progressively refined token maps as hierarchical conditions, and (2) a multistage flow-based distribution modeling method that transforms only partial-denoised distributions at each stage comparing to complete denoising in normal diffusion models. Holistically, ECAR operates by generating tokens at increasing resolutions while simultaneously denoising the image at each stage. This design not only reduces token-to-image transformation cost by a factor of the stage number but also enables parallel processing at the token level. Our approach not only enhances computational efficiency but also aligns naturally with image generation principles by operating in continuous token space and following a hierarchical generation process from coarse to fine details. Experimental results demonstrate that ECAR achieves comparable image quality to DiT Peebles & Xie [2023] while requiring 10$\times$ FLOPs reduction and 5$\times$ speedup to generate a 256$\times$256 image.

스케일 단위 Autoregressive 이미지 생성에 Diffusion을 사용한 Continuous Prediction을 결합한 형태. Diffusion도 모든 스케일에서 전체 스케줄을 진행하는 것이 아니라 각 스케일에 따라 스케줄을 나눠서 진행합니다. VAR과 Transfusion류의 Diffusion을 사용한 접근을 연결한 형태군요. (https://arxiv.org/abs/2404.02905, https://arxiv.org/abs/2408.11039, https://arxiv.org/abs/2412.08635) 이것도 꽤 괜찮을 것 같네요.

<english>
Combination of scale level autoregressive image genration and continuous prediction using diffusion. For diffusions they are not undergone full schedules for each scales, instead schedule is separated for the scales. It is connection of VAR and approaches using diffusions like Transusion (https://arxiv.org/abs/2404.02905, https://arxiv.org/abs/2408.11039, https://arxiv.org/abs/2412.08635). I think this is also viable approach.
</english>

#autoregressive-model #diffusion

# Links

[[240820 Transfusion.md]]
[[240403 Visual Autoregressive Modeling.md]]
[[241211 Multimodal Latent Language Modeling with Next-Token Diffusion.md]]