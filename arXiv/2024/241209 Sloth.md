https://arxiv.org/abs/2412.06540

*Sloth: scaling laws for LLM skills to predict multi-benchmark performance across families* (Felipe Maia Polo, Seamus Somerstep, Leshem Choshen, Yuekai Sun, Mikhail Yurochkin)

> Scaling laws for large language models (LLMs) predict model performance based on parameters like size and training data. However, differences in training configurations and data processing across model families lead to significant variations in benchmark performance, making it difficult for a single scaling law to generalize across all LLMs. On the other hand, training family-specific scaling laws requires training models of varying sizes for every family. In this work, we propose Skills Scaling Laws (SSLaws, pronounced as Sloth), a novel scaling law that leverages publicly available benchmark data and assumes LLM performance is driven by low-dimensional latent skills, such as reasoning and instruction following. These latent skills are influenced by computational resources like model size and training tokens but with varying efficiencies across model families. Sloth exploits correlations across benchmarks to provide more accurate and interpretable predictions while alleviating the need to train multiple LLMs per family. We present both theoretical results on parameter identification and empirical evaluations on 12 prominent benchmarks, from Open LLM Leaderboard v1/v2, demonstrating that Sloth predicts LLM performance efficiently and offers insights into scaling behaviors for downstream tasks such as coding and emotional intelligence applications.

Observational Scaling Law처럼 (https://arxiv.org/abs/2405.10938) Latent Skill을 통한 Task Scaling Law 추정이네요. 여기서는 추출한 Latent Skill에 대해 추론, 지식, Instruction Following이라는 분류도 시도했습니다. 추론 능력은 학습 토큰보다 모델 크기에 영향을 받는다거나 Instruction Tuning에 대한 영향이 뚜렷하지 않다는 것 같은 흥미로운 지점들이 있네요. 

이런 형태의 Latent Skill을 추출했다면 새로운 과제에 대해서도 요인의 가중치를 추정해 큰 모델이 어느 정도의 성능을 보일지를 예측할 수 있죠. 재미있는 방향이라고 생각합니다.

<english>
Similar to observational scaling law (https://arxiv.org/abs/2405.10938) the authors have estimated task scaling law using latent skills. In this study they classified extracted latent skills into reasoning, knowledge, instruction following. There are intresting points such as reasoning skills affect more from model sizes instead of training tokens, and effect of instruction tuning is not very apparent.

If we extracted these kind of latent skills we can predict how large model would perform in new tasks just by estimate weight of factors for that task. I think this is interesting direction.
</english>

#scaling-law

# Links

[[240521 Benchmark Scaling Law.md]]