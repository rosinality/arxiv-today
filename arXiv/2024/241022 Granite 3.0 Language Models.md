https://github.com/ibm-granite/granite-3.0-language-models/blob/main/paper.pdf

*Granite 3.0 Language Models* (Granite Team, IBM)

> This report presents Granite 3.0, a new set of lightweight, state-of-the-art, open foundation models ranging in scale from 400 million to 8 billion active parameters. Equipped with native support of multilingual, coding, function calling, and strong safety performance, these models target enterprise use cases, including on-premise and on-device settings. Evaluations on a comprehensive set of tasks demonstrate that our models consistently reach state-of-the-art performance for their size (as shown in Figure 1 and 2). This report also discloses technical details of pre-training and post-training that may help the research community accelerate the collective efforts to develop open foundation models. We publicly release pre-trained and post-trained versions of all our Granite 3.0 models under a standard permissive Apache 2.0 license allowing both research and commercial use. With support from the open source community, the Granite 3.0 models have been integrated with a range of existing tools for quantization, fine-tuning, and deployment.

IBM의 LLM. Dense 2B, 8B 모델에 대해 12T 학습, 또는 Activated 400M/Weight 1B, Activated 800M/Weight 3B Dropless MoE 모델에 대해 10T 학습. µP, Power Scheduler (https://arxiv.org/abs/2408.13359) 사용. Multi Stage 학습이고 Instruction 데이터를 많이 썼네요. 데이터 비율 결정도 Objective를 설정해 탐색하는 방법을 사용했군요.

정렬 단계에서도 SFT/PPO 외에 Best of N, BRAIn (https://arxiv.org/abs/2402.02479), Reward Model 앙상블, 모델 병합 등 이런 저런 방법을 많이 썼네요. 재미있습니다.

<english>
LLM of IBM. 12T trained dense 2B, 8B models, and 10T trained Dropless MoE models with 400M activated / 1B weights, or 800M activated / 3B weights. µP and Power Scheduler (https://arxiv.org/abs/2408.13359) was used. Multi stage training is employed, and large amout of instruction data was used. Data ratio was configured using search with specific objectives.

For alignment stages Best of N and BRAIn (https://arxiv.org/abs/2402.02479), reward model ensemble, and model merging is used along with SFT and PPO. Interesting.
</english>

#llm #alignment