https://lmsys.org/blog/2024-05-08-llama3/

*What's up with Llama 3? Arena data analysis* (Lisa Dunlap, Evan Frick, Tianle Li, Issac Ong, Joseph E. Gonzalez, Wei-Lin Chiang)

LMSYS에서 챗봇 아레나에서 Llama 3의 승률 분석을 했군요. 예상할 수 있는 것처럼 문제가 어려워질수록 GPT-4, Claude 3 Opus, Gemini 1.5 Pro에 대해 승률이 떨어집니다. 반대로 Creative한 과제에 대해서는 승률이 높은 편이네요.

지금 챗봇이 무엇을 타겟해야 하는지에 대해서 생각해보게 하는군요. 좀 더 어려운 문제를 잘 푼다고 하더라도 그 문제 풀이 능력이 충분한 수준이 아니라면 그 능력이 큰 의미가 없을 수 있겠죠. 좀 더 Creative하거나 더 나은 스타일을 갖는 것이 더 바람직할 것입니다.

그렇지만 고난이도 작업에 대한 능력이 유의미해지고 유용하다면 이 능력에서의 격차가 굉장한 차이를 만들게 되겠죠. 할 수 있는가 혹은 할 수 없는가의 문제로 넘어가는 것이니까요.

사실 통제되지 않는 상황에서의 크라우드소싱 기반 평가 순위 자체는 한계가 있을 수밖에 없는데 그 부분에 대해서 어떻게 접근해야 하는지를 알려줬다는 느낌도 있습니다.

Llama 3가 특유의 스타일을 갖고 있고 평가에 이 스타일이 긍정적으로 작용했을 가능성도 있습니다. 부여하고자 하는 스타일 또한 챗봇에 중요한 요소인데 이 부분에 대한 관심이 부족하지 않았나 하는 생각을 합니다.