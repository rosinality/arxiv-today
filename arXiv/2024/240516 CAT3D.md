https://arxiv.org/abs/2405.10314

*CAT3D: Create Anything in 3D with Multi-View Diffusion Models* (Ruiqi Gao, Aleksander Holynski, Philipp Henzler, Arthur Brussee, Ricardo Martin-Brualla, Pratul Srinivasan, Jonathan T. Barron, Ben Poole)

> Advances in 3D reconstruction have enabled high-quality 3D capture, but require a user to collect hundreds to thousands of images to create a 3D scene. We present CAT3D, a method for creating anything in 3D by simulating this real-world capture process with a multi-view diffusion model. Given any number of input images and a set of target novel viewpoints, our model generates highly consistent novel views of a scene. These generated views can be used as input to robust 3D reconstruction techniques to produce 3D representations that can be rendered from any viewpoint in real-time. CAT3D can create entire 3D scenes in as little as one minute, and outperforms existing methods for single image and few-view 3D scene creation. See our project page for results and interactive demos at https://cat3d.github.io .

https://cat3d.github.io/

이미지 1+장으로 3D 생성. Multi view Diffusion으로 서로 다른 View의 이미지를 여러 장 만들고 NeRF를 학습시키는 형태로 접근했네요. Multi view Diffusion이 핵심일 텐데 비디오 Diffusion처럼 여러 이미지에 대해 Latent Diffusion을 확장하고 카메라 레이의 원점과 방향 정보를 이미지에 붙여서 입력으로 주는 방식입니다.

#3d-generation #diffusion #nerf 