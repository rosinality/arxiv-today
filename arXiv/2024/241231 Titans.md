https://arxiv.org/abs/2501.00663

*Titans: Learning to Memorize at Test Time* (Ali Behrouz, Peilin Zhong, Vahab Mirrokni)

> Over more than a decade there has been an extensive research effort on how to effectively utilize recurrent models and attention. While recurrent models aim to compress the data into a fixed-size memory (called hidden state), attention allows attending to the entire context window, capturing the direct dependencies of all tokens. This more accurate modeling of dependencies, however, comes with a quadratic cost, limiting the model to a fixed-length context. We present a new neural long-term memory module that learns to memorize historical context and helps attention to attend to the current context while utilizing long past information. We show that this neural memory has the advantage of fast parallelizable training while maintaining a fast inference. From a memory perspective, we argue that attention due to its limited context but accurate dependency modeling performs as a short-term memory, while neural memory due to its ability to memorize the data, acts as a long-term, more persistent, memory. Based on these two modules, we introduce a new family of architectures, called Titans, and present three variants to address how one can effectively incorporate memory into this architecture. Our experimental results on language modeling, common-sense reasoning, genomics, and time series tasks show that Titans are more effective than Transformers and recent modern linear recurrent models. They further can effectively scale to larger than 2M context window size with higher accuracy in needle-in-haystack tasks compared to baselines.

모델에 테스트 시점에 저장 가능한 메모리를 추가하는 방법. Test Time Train과 (https://arxiv.org/abs/2407.04620) 비슷하다고 할 수 있겠네요.

학습 시점에 모델을 수정할 수 있는 능력도 중요한 방향이라고 봅니다. 다만 단순히 추가적인 정보를 저장하는 것을 넘어 능력을 수정할 수 있는 것이 필요할 것 같네요. 그건 좀 더 어려운 문제겠죠.

<english>
A method of adding memory that can store information during test time. It is similar to Test Time Train (https://arxiv.org/abs/2407.04620).

I think it is important research direction to add ability to modify the model during test time. But I think beyond merely storing new informations, ability to modifying capabilities is needed. But it would be a harder problem.
</english>

#transformer

# Links

