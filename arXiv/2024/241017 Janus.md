https://arxiv.org/abs/2410.13848

*Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation* (Chengyue Wu, Xiaokang Chen, Zhiyu Wu, Yiyang Ma, Xingchao Liu, Zizheng Pan, Wen Liu, Zhenda Xie, Xingkai Yu, Chong Ruan, Ping Luo)

> In this paper, we introduce Janus, an autoregressive framework that unifies multimodal understanding and generation. Prior research often relies on a single visual encoder for both tasks, such as Chameleon. However, due to the differing levels of information granularity required by multimodal understanding and generation, this approach can lead to suboptimal performance, particularly in multimodal understanding. To address this issue, we decouple visual encoding into separate pathways, while still leveraging a single, unified transformer architecture for processing. The decoupling not only alleviates the conflict between the visual encoder's roles in understanding and generation, but also enhances the framework's flexibility. For instance, both the multimodal understanding and generation components can independently select their most suitable encoding methods. Experiments show that Janus surpasses previous unified model and matches or exceeds the performance of task-specific models. The simplicity, high flexibility, and effectiveness of Janus make it a strong candidate for next-generation unified multimodal models.

DeepSeek의 이미지 생성이 가능한 Multimodal 모델. 이미지 인식에는 SigLIP을 쓰고 생성에는 VQ와 Autoregression을 사용한 방법이군요. 그래서 야누스네요.

실용적으로는 이런 접근이 좋은 방법일 수 있을 텐데 계속 인식과 생성을 동일한 방식으로 하고 싶어지는 이유는 무엇일까요.

<english>
Multimodal model from DeepSeek which is able to generate images. For image recognition SigLIP encoder is used, and for generation VQ and autoregression is used. So named as Janus.

Practically these kind of approaches could be good. But I want the method which reconciles recognition and generation in the same way.
</english>

#autoregressive-model #image-generation #multimodal 