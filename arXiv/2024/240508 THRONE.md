https://arxiv.org/abs/2405.05256

*THRONE: An Object-based Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models* (Prannay Kaul, Zhizhong Li, Hao Yang, Yonatan Dukler, Ashwin Swaminathan, C. J. Taylor, Stefano Soatto)

> Mitigating hallucinations in large vision-language models (LVLMs) remains an open problem. Recent benchmarks do not address hallucinations in open-ended free-form responses, which we term "Type I hallucinations". Instead, they focus on hallucinations responding to very specific question formats -- typically a multiple-choice response regarding a particular object or attribute -- which we term "Type II hallucinations". Additionally, such benchmarks often require external API calls to models which are subject to change. In practice, we observe that a reduction in Type II hallucinations does not lead to a reduction in Type I hallucinations but rather that the two forms of hallucinations are often anti-correlated. To address this, we propose THRONE, a novel object-based automatic framework for quantitatively evaluating Type I hallucinations in LVLM free-form outputs. We use public language models (LMs) to identify hallucinations in LVLM responses and compute informative metrics. By evaluating a large selection of recent LVLMs using public datasets, we show that an improvement in existing metrics do not lead to a reduction in Type I hallucinations, and that established benchmarks for measuring Type I hallucinations are incomplete. Finally, we provide a simple and effective data augmentation method to reduce Type I and Type II hallucinations as a strong baseline.

Vision-Language 모델의 Open-ended Question/Generation 상황에 대한 할루시네이션 벤치마크 방법. 일단 Object Detection 같은 이미지 내에 포함된 객체 레이블이 있는 데이터셋에 대해 캡션을 생성한 다음 LLM으로 캡션에 이미지에 포함되어 있거나 포함되지 않은 객체가 등장하는지를 세는 방법이군요. 자연어에서 원자적 사실을 추출한 다음 각 사실을 점검해서 평가하는 방식들과 비슷할 듯 합니다.

#benchmark #hallucination 