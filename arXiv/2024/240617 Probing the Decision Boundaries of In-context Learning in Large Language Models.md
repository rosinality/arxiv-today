https://arxiv.org/abs/2406.11233

*Probing the Decision Boundaries of In-context Learning in Large Language Models* (Siyan Zhao, Tung Nguyen, Aditya Grover)

> In-context learning is a key paradigm in large language models (LLMs) that enables them to generalize to new tasks and domains by simply prompting these models with a few exemplars without explicit parameter updates. Many attempts have been made to understand in-context learning in LLMs as a function of model scale, pretraining data, and other factors. In this work, we propose a new mechanism to probe and understand in-context learning from the lens of decision boundaries for in-context binary classification. Decision boundaries are straightforward to visualize and provide important information about the qualitative behavior of the inductive biases of standard classifiers. To our surprise, we find that the decision boundaries learned by current LLMs in simple binary classification tasks are often irregular and non-smooth, regardless of linear separability in the underlying task. This paper investigates the factors influencing these decision boundaries and explores methods to enhance their generalizability. We assess various approaches, including training-free and fine-tuning methods for LLMs, the impact of model architecture, and the effectiveness of active prompting techniques for smoothing decision boundaries in a data-efficient manner. Our findings provide a deeper understanding of in-context learning dynamics and offer practical improvements for enhancing robustness and generalizability of in-context learning.

In-context Learning으로 Toy Task들에 대한 분류 과제를 수행하고 Decision Boundary를 추정한 실험. 기본적으로 Decision Boundary는 지저분합니다. 그런데 Classification 과제에 대해 튜닝을 하면 다른 과제에 대해서도 좀 더 깨끗한 Decision Boundary를 갖게 된다고 하네요. 재미있군요.

#in-context-learning 