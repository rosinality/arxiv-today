https://arxiv.org/abs/2405.10286

*FFF: Fixing Flawed Foundations in contrastive pre-training results in very strong Vision-Language models* (Adrian Bulat, Yassine Ouali, Georgios Tzimiropoulos)

> Despite noise and caption quality having been acknowledged as important factors impacting vision-language contrastive pre-training, in this paper, we show that the full potential of improving the training process by addressing such issues is yet to be realized. Specifically, we firstly study and analyze two issues affecting training: incorrect assignment of negative pairs, and low caption quality and diversity. Then, we devise effective solutions for addressing both problems, which essentially require training with multiple true positive pairs. Finally, we propose training with sigmoid loss to address such a requirement. We show very large gains over the current state-of-the-art for both image recognition (∼ +6% on average over 11 datasets) and image retrieval (∼ +19% on Flickr30k and ∼ +15% on MSCOCO).

CLIP 개선. 이미지-이미지, 이미지-텍스트, 텍스트-텍스트 유사도를 사용해 False negative에서 Positive 페어를 발굴합니다. 추가로 이미지에 대해 캡션을 여러 개 만들어서 추가 Positive 페어로 사용합니다.

원칙적으로는 Distillation이긴 하네요.

#vision-language #contrastive-learning 
