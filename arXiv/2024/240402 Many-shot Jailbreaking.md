https://www.anthropic.com/research/many-shot-jailbreaking

Many-shot Jailbreaking (Cem Anil, Esin Durmus, Mrinank Sharma, Joe Benton, Sandipan Kundu, Joshua Batson, Nina Rimsky, Meg Tong, Jesse Mu, Daniel Ford, Francesco Mosconi, Rajashree Agrawal, Rylan Schaeffer, Naomi Bashkansky, Samuel Svenningsen, Mike Lambert, Ansh Radhakrishnan, Carson Denison, Evan J Hubinger, Yuntao Bai, Trenton Bricken, Timothy Maxwell, Nicholas Schiefer, Jamie Sully, Alex Tamkin, Tamera Lanham, Karina Nguyen, Tomasz Korbak, Jared Kaplan, Deep Ganguli, Samuel R. Bowman, Ethan Perez, Roger Grosse, David Duvenaud)

https://cdn.sanity.io/files/4zrzovbb/website/af5633c94ed2beb282f6a53c595eb437e8e7b630.pdf#page=1.58

사용자의 악의적인 질문에 모델이 답을 하는 형태의 샘플을 입력으로 주는 것으로 탈옥하는 방법. 샘플이 늘어나고 모델이 클수록 잘 뚫립니다. 이를 타겟해서 SFT/RL을 하면 도움이 되긴 하지만 문제를 해소하진 못하는군요.

효과가 컸던 것은 프롬프트에 네가 지켜야 할 원칙에 위배되지 않을 때에만 답하라고 앞뒤에 붙이는 방식이었습니다. 일반적인 답에 대해서 패턴을 어떻게 바꾸는지는 아직 결과가 없네요.

#safety 