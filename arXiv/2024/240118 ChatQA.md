https://arxiv.org/abs/2401.10225

*ChatQA: Building GPT-4 Level Conversational QA Models* (Zihan Liu, Wei Ping, Rajarshi Roy, Peng Xu, Mohammad Shoeybi, Bryan Catanzaro)

> In this work, we introduce ChatQA, a family of conversational question answering (QA) models, that obtain GPT-4 level accuracies. Specifically, we propose a two-stage instruction tuning method that can significantly improve the zero-shot conversational QA results from large language models (LLMs). To handle retrieval in conversational QA, we fine-tune a dense retriever on a multi-turn QA dataset, which provides comparable results to using the state-of-the-art query rewriting model while largely reducing deployment cost. Notably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10 conversational QA datasets (54.14 vs. 53.90), without relying on any synthetic data from OpenAI GPT models.

NVIDIA의 Retrieval 기반 QA 모델. NVIDIA는 Retrieval을 꽤 좋아하네요. SFT 이후 문서를 컨텍스트로 하는 QA 데이터로 다시 튜닝했습니다. 추가적으로 멀티 턴 상황에서 Retriever가 적절한 문서를 가져올 수 있도록 Retriever를 파인튜닝하는 작업도 했습니다.

#qa