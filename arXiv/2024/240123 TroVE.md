https://arxiv.org/abs/2401.12869

*TroVE: Inducing Verifiable and Efficient Toolboxes for Solving Programmatic Tasks* (Zhiruo Wang, Daniel Fried, Graham Neubig)

> Language models (LMs) can solve tasks such as answering questions about tables or images by writing programs. However, using primitive functions often leads to verbose and error-prone programs, and higher-level functions require expert design. To enable better solutions without human labor, we ask code LMs to curate reusable high-level functions, and use them to write solutions. We present TROVE, a training-free method of inducing a verifiable and efficient toolbox of functions, by generating via using, growing, and periodically trimming the toolbox. On 11 datasets from math, table question answering, and image reasoning tasks, TROVE consistently yields simpler solutions with higher accuracy than baselines using CODELLAMA and previous methods using GPT, while using 79-98% smaller toolboxes. TROVE further enables 31% faster and 13% more accurate human verification than baselines. With the same pipeline, it creates diverse functions for varied tasks and datasets, providing insights into their individual characteristics.

LM이 코드 작성으로 문제를 풀 때 기초적인 함수만으로 코드를 구성하는 것이 아니라 적절하게 필요한 고수준의 함수를 작성하고, 이 함수들로 구성된 도구 상자를 유지하면서 코드를 작성하는 접근이군요.

#code 