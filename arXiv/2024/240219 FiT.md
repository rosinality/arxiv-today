https://arxiv.org/abs/2402.12376

*FiT: Flexible Vision Transformer for Diffusion Model* (Zeyu Lu, Zidong Wang, Di Huang, Chengyue Wu, Xihui Liu, Wanli Ouyang, Lei Bai)

> Nature is infinitely resolution-free. In the context of this reality, existing diffusion models, such as Diffusion Transformers, often face challenges when processing image resolutions outside of their trained domain. To overcome this limitation, we present the Flexible Vision Transformer (FiT), a transformer architecture specifically designed for generating images with unrestricted resolutions and aspect ratios. Unlike traditional methods that perceive images as static-resolution grids, FiT conceptualizes images as sequences of dynamically-sized tokens. This perspective enables a flexible training strategy that effortlessly adapts to diverse aspect ratios during both training and inference phases, thus promoting resolution generalization and eliminating biases induced by image cropping. Enhanced by a meticulously adjusted network structure and the integration of training-free extrapolation techniques, FiT exhibits remarkable flexibility in resolution extrapolation generation. Comprehensive experiments demonstrate the exceptional performance of FiT across a broad range of resolutions, showcasing its effectiveness both within and beyond its training resolution distribution. Repository available at https://github.com/whlzy/FiT.

2D RoPE, 임의 Aspect Ratio를 Diffusion Transformer에 적용해본 실험. 최대 길이 패딩을 사용한 방법입니다. 2D RoPE와 Sequence Packing을 사용하는 방법을 Unified-IO 2 (https://arxiv.org/abs/2312.17172) 에서 채택했는데 같이 보는 것도 재미있을 것 같네요. Sora의 디테일을 상상해보려면 특히.

#diffusion #transformer

# Links

[[231228 Unified-IO 2.md]]