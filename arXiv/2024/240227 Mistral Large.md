https://mistral.ai/news/mistral-large/

Mistral의 고성능 지향 모델이 하나 나왔군요. MMLU 81.2% 정도의 모델입니다. Mistral Small이라는 Mixtral 8x7B보다 레이턴시가 낮고 고성능인 모델도 같이 나왔습니다. Azure에서 서빙하고 Self Deployment도 가능하다고 하는군요. (비용이 문제겠지만요.)

API 비용을 보면 입력 기준으로 Mistral Small이 2$ / 1M으로 Mixtral 8x7B의 0.7$ / 1M보다 비쌉니다. Mistral Large는 8$ / 1M으로 GPT-4 Turbo의 10$ / 1M 보다 20% 정도 저렴한 정도네요. 그러나 토크나이저 효율성의 차이에 따라 실질 비용이 달라질 수 있겠네요.

제 소감은 다음과 같습니다.

1. MMLU가 전부는 아니지만 MMLU 80% 초반을 벗어나는 것은 쉬운 일이 아니다. 아직까지도 5-shot으로 85%를 넘은 사례는 GPT-4가 유일하네요. 80% 후반으로 가기 위해서 필요한 연산량이 엄청나다는 의미가 아닐지. (즉 많은 사람들이 기대하던 연산량을 유의미한 수준으로 절감하는 방법은 아직 없다는 것이죠.)
2. 고성능으로 갈수록 비용도 결국 GPT-4 수준으로 수렴한다. 물론 지금 수준에서는 비용 경쟁력이 애매해서 비용이 조정될 수도 있겠지만요. 이 또한 모델 크기를 획기적으로 줄일 수 있는 방법이 없다는 의미겠죠.
3. Mistral Medium의 초기 버전이 유출되는 사고가 있긴 했습니다만 여하간 Mistral Medium을 오픈하지 않은 상태에서 Mistral Large를 다시 API만 공개했다는 것은 앞으로도 Mistral이 Cutting Edge 모델들을 오픈하지 않으리라는 의미가 아닐까 싶습니다.

3번의 측면에서는 앞으로 최고 성능 모델이 나오기를 기대할 수 있는 것은 메타의 Llama 정도가 유일해지지 않을까 싶네요. 중국 모델들도 점점 오픈하지 않는 사례가 늘어나지 않을까 싶습니다.

그래서 투자 비용을 어떻게 회수할 것인가라는 질문에서 생각해보면 당연한 흐름이라고 할 수 있겠죠. 메타 같이 그 문제가 급하지 않은 곳에서만 가능하지 않을까 싶습니다. (개인적으로는 메타도 마냥 오픈하기가 쉽지는 않은 상황이 되지 않을까 하는 생각도 있습니다. "그렇게 강력한 모델이 공개되어서는 안 된다"라는 국가적 압박이 발생할 가능성도 있지 않을까 싶어서요.)

더 개인적인 소회입니다만 전 Mistral이 벤치마크 스코어와 체크포인트만 공개해왔던 행보가 (많은 사람들이 열광해왔던 것과는 달리) 마냥 오픈이라고 하기 어려운 행보라고 생각했었던 터라 그렇게 놀라운 일은 아니지 않나 하는 생각을 합니다. Mistral 7B만 해도 어느 정도의 데이터에 학습시켰는지 아직도 알려지지 않았죠.


https://mistral.ai/news/mistral-large/

Mistral의 고성능 지향 모델이 하나 나왔다. MMLU 81.2% 정도의 모델. Mistral Small이라는 Mixtral 8x7B보다 레이턴시가 낮고 고성능인 모델도 같이 나왔다. Azure에서 서빙하고 Self Deployment도 가능하다고. (비용이 문제겠지만.)

API 비용을 보면 입력 기준으로 Mistral Small이 2$ / 1M으로 Mixtral 8x7B의 0.7$ / 1M보다 비싸다. Mistral Large는 8$ / 1M으로 GPT-4 Turbo의 10$ / 1M 보다 20% 정도 저렴한 정도. 그러나 토크나이저 효율성의 차이에 따라 실질 비용이 달라질 수 있겠다.

내 소감은 다음과 같다.

1. MMLU가 전부는 아니지만 MMLU 80% 초반을 벗어나는 것은 쉬운 일이 아니다. 아직까지도 5-shot으로 85%를 넘은 사례는 GPT-4가 유일. 80% 후반으로 가기 위해서 필요한 연산량이 엄청나다는 의미가 아닐지. (즉 많은 사람들이 기대하던 연산량을 유의미한 수준으로 절감하는 방법은 아직 없다는 것.)
2. 고성능으로 갈수록 비용도 결국 GPT-4 수준으로 수렴한다. 물론 지금 수준에서는 비용 경쟁력이 애매해서 비용이 조정될 수도 있겠지만. 이 또한 모델 크기를 획기적으로 줄일 수 있는 방법이 없다는 의미.
3. Mistral Medium의 초기 버전이 유출되는 사고가 있긴 했습니다만 여하간 Mistral Medium을 오픈하지 않은 상태에서 Mistral Large를 다시 API만 공개했다는 것은 앞으로도 Mistral이 Cutting Edge 모델들을 오픈하지 않으리라는 의미가 아닐까 싶음.

3번의 측면에서는 앞으로 최고 성능 모델이 나오기를 기대할 수 있는 것은 메타의 Llama 정도가 유일해지지 않을까 싶다. 중국 모델들도 점점 오픈하지 않는 사례가 늘어나지 않을까 싶음.

그래서 투자 비용을 어떻게 회수할 것인가라는 질문에서 생각해보면 당연한 흐름이라고 할 수 있을 것. 메타 같이 그 문제가 급하지 않은 곳에서만 가능하지 않을까 싶다. (개인적으로는 메타도 마냥 오픈하기가 쉽지는 않은 상황이 되지 않을까 하는 생각도 있다. "그렇게 강력한 모델이 공개되어서는 안 된다"라는 국가적 압박이 발생할 가능성도 있지 않을까 싶음.)

더 개인적인 소회이지만 Mistral이 벤치마크 스코어와 체크포인트만 공개해왔던 행보가 (많은 사람들이 열광해왔던 것과는 달리) 마냥 오픈이라고 하기 어려운 행보라고 생각했었던 터라 그렇게 놀라운 일은 아니지 않나 하는 생각을 한다. Mistral 7B만 해도 어느 정도의 데이터에 학습시켰는지 아직도 알려지지 않았으니.