https://arxiv.org/abs/2409.12186

*Qwen2.5-Coder Technical Report* (Binyuan Hui, Jian Yang, Zeyu Cui, Jiaxi Yang, Dayiheng Liu, Lei Zhang, Tianyu Liu, Jiajun Zhang, Bowen Yu, Kai Dang, An Yang, Rui Men, Fei Huang, Xingzhang Ren, Xuancheng Ren, Jingren Zhou, Junyang Lin)

> In this report, we introduce the Qwen2.5-Coder series, a significant upgrade from its predecessor, CodeQwen1.5. This series includes two models: Qwen2.5-Coder-1.5B and Qwen2.5-Coder-7B. As a code-specific model, Qwen2.5-Coder is built upon the Qwen2.5 architecture and continues pretrained on a vast corpus of over 5.5 trillion tokens. Through meticulous data cleaning, scalable synthetic data generation, and balanced data mixing, Qwen2.5-Coder demonstrates impressive code generation capabilities while retaining general versatility. The model has been evaluated on a wide range of code-related tasks, achieving state-of-the-art (SOTA) performance across more than 10 benchmarks, including code generation, completion, reasoning, and repair, consistently outperforming larger models of the same model size. We believe that the release of the Qwen2.5-Coder series will not only push the boundaries of research in code intelligence but also, through its permissive licensing, encourage broader adoption by developers in real-world applications.

Qwen 2.5 Coder. 코드와 코드 관련 데이터를 수집하고, 데이터 생성하고, 수학 데이터를 사용. Common Crawl에서 데이터를 수집하는 작업도 했는데 DeepSeekMath와는 달리 URL 기반이 아니라 Coarse-to-Fine 필터링을 했다고 하는데...디테일이 나와 있지는 않네요. 느낌으로는 잠재적으로 코드와 관련이 없는 데이터도 성기게 수집한 다음 점진적으로 코드 관련성이 높은 데이터를 추려나가는 작업을 한 것이 아닌가 싶습니다.

그리고 이렇게 구축한 데이터로 5.5T 학습. 5.2T는 파일 단위로 학습하고 300B는 Long Context Extension을 한 다음 레포 레벨로 학습했습니다.

Instruction은 코드 스니펫에서 Instruction을 생성한 다음 코드를 생성하고 스니펫과 비교해서 필터링, Multi Agent 세팅으로 Multilingual 데이터 생성, Instruction 데이터에 대해 체크리스트를 만들고 (코드가 정확한가, 명료한가 등) 평가, 그리고 샌드박스 내에서 유닛 테스트를 생성하고 테스트하는 등의 과정을 진행. 데이터 관련 작업이 정말 많긴 합니다.

#code #llm 