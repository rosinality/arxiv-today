https://arxiv.org/abs/2406.14532

*RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold* (Amrith Setlur, Saurabh Garg, Xinyang Geng, Naman Garg, Virginia Smith, Aviral Kumar)

> Training on model-generated synthetic data is a promising approach for finetuning LLMs, but it remains unclear when it helps or hurts. In this paper, we investigate this question for math reasoning via an empirical study, followed by building a conceptual understanding of our observations. First, we find that while the typical approach of finetuning a model on synthetic correct or positive problem-solution pairs generated by capable models offers modest performance gains, sampling more correct solutions from the finetuned learner itself followed by subsequent fine-tuning on this self-generated data $\textbf{doubles}$ the efficiency of the same synthetic problems. At the same time, training on model-generated positives can amplify various spurious correlations, resulting in flat or even inverse scaling trends as the amount of data increases. Surprisingly, we find that several of these issues can be addressed if we also utilize negative responses, i.e., model-generated responses that are deemed incorrect by a final answer verifier. Crucially, these negatives must be constructed such that the training can appropriately recover the utility or advantage of each intermediate step in the negative response. With this per-step scheme, we are able to attain consistent gains over only positive data, attaining performance similar to amplifying the amount of synthetic data by $\mathbf{8 \times}$. We show that training on per-step negatives can help to unlearn spurious correlations in the positive data, and is equivalent to advantage-weighted reinforcement learning (RL), implying that it inherits robustness benefits of RL over imitating positive data alone.

합성 데이터를 사용해 수학 문제를 푸는 능력을 주입한 실험. 요점은 1. 더 강력한 모델로 생성한 데이터보다 모델 자체가 생성한 데이터 중 Positive를 걸러서 학습시키는 것이 더 데이터 효율적이다. 2. 그렇지만 Positive만 사용해서 학습하면 잘못된 패턴을 학습하는 위험이 있다. (Spurious Correlation) 3. Negative 샘플을 사용해 중요한 스텝을 부각시킬 수 있고 이것이 데이터 효율성을 크게 향상시킨다.

#rlaif 