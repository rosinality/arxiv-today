https://arxiv.org/abs/2401.08525

*GATS: Gather-Attend-Scatter* (Konrad Zolna, Serkan Cabi, Yutian Chen, Eric Lau, Claudio Fantacci, Jurgis Pasukonis, Jost Tobias Springenberg, Sergio Gomez Colmenarejo)

> As the AI community increasingly adopts large-scale models, it is crucial to develop general and flexible tools to integrate them. We introduce Gather-Attend-Scatter (GATS), a novel module that enables seamless combination of pretrained foundation models, both trainable and frozen, into larger multimodal networks. GATS empowers AI systems to process and generate information across multiple modalities at different rates. In contrast to traditional fine-tuning, GATS allows for the original component models to remain frozen, avoiding the risk of them losing important knowledge acquired during the pretraining phase. We demonstrate the utility and versatility of GATS with a few experiments across games, robotics, and multimodal input-output systems.

여러 모델들을 연결하는 방법. 서로 다른 모델의 레이어들 사이에 GATS라는 모델의 레이어들을 끼워넣는 방식입니다. GATS는 서로 다른 모델의 임베딩에서 각각 최근 임베딩 N개를 가져와서 Attention하고 원 모델의 임베딩으로 Projection 하는 구조네요.

로봇 조작이나 게임 같은 걸 하다가 아주 가볍게(?) MaskGIT과 Chinchilla LM을 GATS로 연결해서 ViT를 학습하는 것과 ViT와 Chinchilla LM을 GATS로 조합하고 MaskGIT & Autoregressive LM으로 학습해서 이미지 캡셔닝과 Text2Image 학습을 한 사례를 보여줍니다.

#multimodal #adapter #efficient_training 