https://arxiv.org/abs/2409.20566

*MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning* (Haotian Zhang, Mingfei Gao, Zhe Gan, Philipp Dufter, Nina Wenzel, Forrest Huang, Dhruti Shah, Xianzhi Du, Bowen Zhang, Yanghao Li, Sam Dodge, Keen You, Zhen Yang, Aleksei Timofeev, Mingze Xu, Hong-You Chen, Jean-Philippe Fauconnier, Zhengfeng Lai, Haoxuan You, Zirui Wang, Afshin Dehghan, Peter Grasch, Yinfei Yang)

> We present MM1.5, a new family of multimodal large language models (MLLMs) designed to enhance capabilities in text-rich image understanding, visual referring and grounding, and multi-image reasoning. Building upon the MM1 architecture, MM1.5 adopts a data-centric approach to model training, systematically exploring the impact of diverse data mixtures across the entire model training lifecycle. This includes high-quality OCR data and synthetic captions for continual pre-training, as well as an optimized visual instruction-tuning data mixture for supervised fine-tuning. Our models range from 1B to 30B parameters, encompassing both dense and mixture-of-experts (MoE) variants, and demonstrate that careful data curation and training strategies can yield strong performance even at small scales (1B and 3B). Additionally, we introduce two specialized variants: MM1.5-Video, designed for video understanding, and MM1.5-UI, tailored for mobile UI understanding. Through extensive empirical studies and ablations, we provide detailed insights into the training processes and decisions that inform our final designs, offering valuable guidance for future research in MLLM development.

MM1.5. MM1에 (https://arxiv.org/abs/2403.09611) 이어 Ablation이 꽤 상세하군요. 이미지 그리드를 이미지 종횡비에 따라 바꾼다거나 (Dynamic Splitting) OCR 데이터와 고해상도 학습의 효과 등에 대한 실험을 진행했습니다.

<english>
MM1.5. Like MM1 (https://arxiv.org/abs/2403.09611) they shows quite detailed ablation studies. They conducted experiments on various modeling choices, such as dynamic splitting which adjusts image grid based on aspect ratios, and the effects of using OCR data and high-resolution training.
</english>

#vision-language

# Links

[[240314 MM1.md]]