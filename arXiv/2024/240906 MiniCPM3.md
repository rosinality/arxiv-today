https://huggingface.co/openbmb/MiniCPM3-4B

*MiniCPM3-4B* (OpenBNB)

MiniCPM3가 나왔습니다. 특징적으로는 굉장히 깊고 (62 레이어입니다) MLA를 사용했다는 것이네요. (https://arxiv.org/abs/2405.04434)

MLA는 GQA보다 가벼우면서 동시에 고성능이라는 점에서 매력적인 선택지인 듯 합니다. 다만 Positional Encoding 차원에 제약이 걸린다는 것이 아쉬운 부분이죠. 특히 Long Context에 대해서 Gemma 스타일처럼 256 차원 정도의 큰 차원을 사용하는 것이 도움이 되지 않을까 하는 생각이 있습니다.

#llm 