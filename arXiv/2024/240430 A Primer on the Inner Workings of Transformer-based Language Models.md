https://arxiv.org/abs/2405.00208

*A Primer on the Inner Workings of Transformer-based Language Models* (Javier Ferrando, Gabriele Sarti, Arianna Bisazza, Marta R. Costa-jussà)

> The rapid progress of research aimed at interpreting the inner workings of advanced language models has highlighted a need for contextualizing the insights gained from years of work in this area. This primer provides a concise technical introduction to the current techniques used to interpret the inner workings of Transformer-based language models, focusing on the generative decoder-only architecture. We conclude by presenting a comprehensive overview of the known internal mechanisms implemented by these models, uncovering connections across popular approaches and active research directions in this area.

트랜스포머 모델 분석에 대한 리뷰군요. Mechanistic Interpretability를 위시해서 Interpretability 문제가 지금처럼 인기 있었던 적이 없는 것 같네요.

#transformer 